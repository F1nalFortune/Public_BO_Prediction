{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get, ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from time import sleep, time\n",
    "import time\n",
    "from random import randint\n",
    "from IPython.core.display import clear_output\n",
    "from warnings import warn\n",
    "import numpy as np\n",
    "from functools import wraps\n",
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry(ExceptionToCheck, tries=20, delay=3, backoff=2, logger=None):\n",
    "  \"\"\"\n",
    "    Modified from source: http://wiki.python.org/moin/PythonDecoratorLibrary#Retry\n",
    "\n",
    "    Objective\n",
    "    ----------\n",
    "    Exponential backoff function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ExceptionToCheck : Exception or tuple\n",
    "      the exception to check. may be a tuple of exceptions to check\n",
    "      Possible values:\n",
    "        ConnectionResetError, (TimeoutError, ConnectionError)\n",
    "    tries : int\n",
    "      number of times to try (not retry) before giving up\n",
    "    delay : int\n",
    "      initial delay between retries in seconds\n",
    "    backoff: int\n",
    "      backoff multiplier\n",
    "      E.g. value of 2 will double the delay each retry\n",
    "    logger : logging.Logger instance\n",
    "      logger to use\n",
    "  \"\"\"\n",
    "  def deco_retry(f):\n",
    "    @wraps(f)\n",
    "    def f_retry(*args, **kwargs):\n",
    "      mtries, mdelay = tries, delay\n",
    "      while mtries > 1:\n",
    "        try:\n",
    "          return f(*args, **kwargs)\n",
    "        except ExceptionToCheck:\n",
    "          msg = \"%s, Retrying in %d seconds...\" % (str(ExceptionToCheck), mdelay)\n",
    "          if logger:\n",
    "            #logger.exception(msg) # would print stack trace\n",
    "            logger.warning(msg)\n",
    "          else:\n",
    "            print(msg)\n",
    "          time.sleep(mdelay)\n",
    "          mtries -= 1\n",
    "          mdelay *= backoff\n",
    "        return f(*args, **kwargs)\n",
    "      return f_retry  # true decorator\n",
    "  return deco_retry  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data in lists\n",
    "def scrapeMovies(links, path, thread):\n",
    "  \"\"\"\n",
    "    Objective\n",
    "    ----------\n",
    "    Crawl data in a timely manner from IMDb.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    links : list\n",
    "      specific URLs of web pages to crawl.\n",
    "    path : string\n",
    "      where to save the file.\n",
    "    thread : string\n",
    "      unique thread number.\n",
    "  \"\"\"\n",
    "  movies = pd.DataFrame()\n",
    "  movies.to_csv(f\"{path}full_{thread}.csv\")\n",
    "  requests = 0\n",
    "  #for every page\n",
    "  count=0\n",
    "  for link in links:\n",
    "      count+=1\n",
    "#       movies = pd.read_csv(f\"{path}full_two.csv\")\n",
    "      #make get request\n",
    "      \n",
    "      @retry((ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2,backoff=2)\n",
    "      def get_response():\n",
    "        response = get(link)\n",
    "        return response\n",
    "      response = get_response()\n",
    "\n",
    "      # parse the content of request\n",
    "      page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "      #select all 250 movie containers from a single page\n",
    "      mv_containers = page_html.find_all('div', class_ = 'lister-item mode-advanced')\n",
    "\n",
    "      # Extract data from indiv. movie containers\n",
    "      for container in mv_containers:\n",
    "          count+=1\n",
    "          profile = container.h3.a['href']\n",
    "          @retry((ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2, backoff=2)\n",
    "          def get_details():\n",
    "            details = get(\"https://www.imdb.com\" + profile)\n",
    "            return details\n",
    "          details = get_details()\n",
    "          # parse the content of request\n",
    "          details_html = BeautifulSoup(details.text, 'html.parser')\n",
    "\n",
    "    #         '''\n",
    "    #             GRAB MOVIE NAME\n",
    "    #         '''\n",
    "          name = container.h3.a.text\n",
    "          print(Fore.GREEN + f\"{name}({count})\")\n",
    "\n",
    "          '''\n",
    "            GRAB PLOT SYNOPSIS\n",
    "          '''\n",
    "          try:\n",
    "            synopsis_link = profile\n",
    "            @retry((ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2, backoff=2)\n",
    "            def get_synopsis():\n",
    "              synopsis = get(\"https://www.imdb.com/\" + synopsis_link + \"plotsummary\")\n",
    "              return synopsis\n",
    "            synopsis = get_synopsis()\n",
    "            synopsis_html = BeautifulSoup(synopsis.text, 'html.parser')\n",
    "\n",
    "            plot_synopsis_content = synopsis_html.find(\"ul\", {\"id\": \"plot-synopsis-content\"}).li.text\n",
    "            plot_synopsis_content = plot_synopsis_content.strip()\n",
    "            if plot_synopsis_content[:58] != \"It looks like we don't have a Synopsis for this title yet.\":\n",
    "              print(Fore.GREEN + 'Plot Synopsis')\n",
    "            else:\n",
    "              plot_synopsis_content = np.nan\n",
    "              print(Fore.RED + 'Plot Synopsis')\n",
    "          except:\n",
    "            plot_synopsis_content = np.nan\n",
    "            print(Fore.RED + 'Plot Synopsis')\n",
    "              \n",
    "              \n",
    "          '''\n",
    "              GRAB SUMMARY\n",
    "          '''\n",
    "          \n",
    "          try:\n",
    "            summary = details_html.find('div', class_='summary_text').text.strip()\n",
    "            print(Fore.GREEN + 'Summary')\n",
    "          except:\n",
    "            summary = np.nan\n",
    "            print(Fore.RED + 'Summary')\n",
    "            \n",
    "          '''\n",
    "            GRAB LANGUAGES\n",
    "          '''\n",
    "          \n",
    "          try:\n",
    "            languages = details_html.find(text='Language:').parent.parent.text.strip().replace(\"Language:\", \"\").replace(\"\\n\", \"\")\n",
    "            print(Fore.GREEN + 'Languages')\n",
    "          except:\n",
    "            languages = np.nan\n",
    "            print(Fore.RED + 'Languages')\n",
    "              \n",
    "              \n",
    "          '''\n",
    "              GRAB BOX OFFICE GROSS\n",
    "          '''\n",
    "          try:\n",
    "              #Gross\n",
    "              bo = details_html.find(text='Gross USA:').parent.findNext('span').decompose()\n",
    "              bo_gross = details_html.find(text='Gross USA:').parent.parent.text.strip()\n",
    "              bo_gross = bo_gross.replace(\"Gross USA:\", \"\").replace(',', '').strip()\n",
    "              dom_gross = bo_gross\n",
    "              print(Fore.GREEN + 'Box Office Gross: {}'.format(bo_gross))\n",
    "\n",
    "          except:\n",
    "              dom_gross = np.nan\n",
    "              print(Fore.RED + 'Box Office Gross: Null')\n",
    "\n",
    "          '''\n",
    "              GRAB WORLDWIDE BOX OFFICE GROSS\n",
    "          '''\n",
    "          try:\n",
    "              #Gross\n",
    "              bo = details_html.find(text='Cumulative Worldwide Gross:').parent.findNext('span').decompose()\n",
    "              bo_gross = details_html.find(text='Cumulative Worldwide Gross:').parent.parent.text.strip()\n",
    "              bo_gross = bo_gross.replace(\"Cumulative Worldwide Gross:\", \"\").replace(',', '').strip()\n",
    "              int_gross = bo_gross\n",
    "              print(Fore.GREEN + 'WorldWide Box Office Gross: {}'.format(bo_gross))\n",
    "\n",
    "          except:\n",
    "              int_gross = np.nan\n",
    "              print(Fore.RED + 'WorldWide Box Office Gross: Null')\n",
    "\n",
    "\n",
    "          '''\n",
    "              GRAB RUNTIME\n",
    "          '''\n",
    "\n",
    "          try:\n",
    "              runtime = container.find('span', class_ = 'runtime').text\n",
    "              print(Fore.GREEN + 'Runtime : {}'.format(runtime))\n",
    "          except:\n",
    "              runtime = np.nan\n",
    "              print(Fore.GREEN + 'Runtime : Null')\n",
    "              \n",
    "          '''\n",
    "            GET SOUNDMIX\n",
    "          '''\n",
    "          try:\n",
    "              #Gross\n",
    "            sound_mix = details_html.find(text='Sound Mix:').parent.parent.text.replace(\"Sound Mix:\", \"\").replace(\"\\n\", \"\").strip()\n",
    "            sound_mix = sound_mix.strip().split(\"|\")\n",
    "            tot_sound_mix = []\n",
    "            for val in sound_mix:\n",
    "              tot_sound_mix.append(re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", val.strip()))\n",
    "            sound_mix = tot_sound_mix\n",
    "            print(Fore.GREEN + 'Soundmix')\n",
    "\n",
    "          except:\n",
    "            sound_mix = np.nan\n",
    "            print(Fore.RED + 'Soundmix')\n",
    "            \n",
    "            \n",
    "          '''\n",
    "            MOVIE STARS\n",
    "          '''\n",
    "          p_tags = container.find_all('p')\n",
    "          try:\n",
    "            stars = details_html.find('h4', text='Stars:').parent.find_all('a')\n",
    "            all_stars = []\n",
    "            all_anchs = []\n",
    "            for value in stars:\n",
    "              if 'See full cast' not in value.text:\n",
    "                star = value.text\n",
    "                anch = value['href']\n",
    "                all_stars.append(star)\n",
    "                all_anchs.append(anch)\n",
    "                \n",
    "                \n",
    "            stars = all_stars\n",
    "            star_anchs = all_anchs\n",
    "            print(Fore.GREEN + 'Stars')\n",
    "\n",
    "          except:\n",
    "            stars = np.nan\n",
    "            star_anchs = np.nan\n",
    "            print(Fore.RED + 'Stars')\n",
    "          '''\n",
    "              GRAB CAST\n",
    "          '''\n",
    "          try: \n",
    "              cast_anchors = []\n",
    "              @retry((ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2, backoff=2)\n",
    "              def get_cast():\n",
    "                  cast = get(\"https://www.imdb.com/\" + profile + \"fullcredits\")\n",
    "                  return cast\n",
    "              cast = get_cast()\n",
    "              cast_html = BeautifulSoup(cast.text, 'html.parser')\n",
    "              #cast\n",
    "              cast_html.find('table', class_ = 'cast_list').findNext('tr').decompose()\n",
    "              cast_members = []\n",
    "              cast_odd = cast_html.find('table', class_ = 'cast_list').findAll('tr', class_='odd')\n",
    "              cast_even = cast_html.find('table', class_ = 'cast_list').findAll('tr', class_='even')\n",
    "              for cast in cast_odd:\n",
    "                  cast_members.append(cast.findAll('td')[1].text.strip())\n",
    "                  anchor = cast.findAll('td')[1].a['href']\n",
    "                  cast_anchors.append(cast.findAll('td')[1].a['href'])\n",
    "              for cast in cast_even:\n",
    "                  cast_members.append(cast.findAll('td')[1].text.strip())\n",
    "                  anchor = cast.findAll('td')[1].a['href']\n",
    "                  cast_anchors.append(cast.findAll('td')[1].a['href'])\n",
    "#               print(f\"Cast Anchors: {cast_anchors}\")\n",
    "              print(Fore.GREEN + 'Cast')\n",
    "          except:\n",
    "              cast_anchors = np.nan\n",
    "              cast_members = np.nan\n",
    "              print(Fore.RED + 'Cast')\n",
    "          '''\n",
    "              GET DIRECTORS\n",
    "          '''\n",
    "          #Director\n",
    "          try:\n",
    "              director_anchors = []\n",
    "              all_directors = []\n",
    "              director_credits = []\n",
    "              rows = cast_html.find('div', attrs = {'id': 'fullcredits_content'}).table.find_all('tr')\n",
    "              for row in rows:\n",
    "                director = row.find('td', class_ = 'name').a.text.replace(\"\\n\", \"\").strip()\n",
    "                \n",
    "                if re.search('[a-zA-Z]', director) and director != \"\":\n",
    "                    all_directors.append(director.strip())\n",
    "                    anchor = row.find('td', class_ = 'name').a['href']\n",
    "                    try:\n",
    "                      credit = row.find('td', class_='credit').text.strip()\n",
    "                    except:\n",
    "                      credit = np.nan\n",
    "                    director_credits.append(credit)\n",
    "                    director_anchors.append(anchor)\n",
    "                else:\n",
    "                    all_directors.append('null')\n",
    "              cleaned_directors = []\n",
    "              for director in all_directors:\n",
    "                  if len(all_directors) > 0:\n",
    "                      if director != \"\":\n",
    "                          cleaned_directors.append(director)\n",
    "                      else:\n",
    "                        cleaned_directors.append(np.nan)\n",
    "                  else:\n",
    "                    cleaned_directors.append(np.nan)\n",
    "              directors = cleaned_directors\n",
    "              print(f\"Anchors: {director_anchors}\")\n",
    "          except:\n",
    "              director_anchors = np.nan\n",
    "              directors = np.nan\n",
    "              director_credits = np.nan\n",
    "              print(Fore.RED + 'Directors')\n",
    "\n",
    "          '''\n",
    "              GRAB CINEMATOGRAPHER\n",
    "          '''\n",
    "          try: \n",
    "            cin_flag = False\n",
    "            divs = cast_html.find_all('h4')\n",
    "            for div in divs:\n",
    "              if 'Cinematography by' in div.text:\n",
    "                cin_flag = True\n",
    "                cinematographer = div.find_next('table').tbody.tr.td.a.text\n",
    "                cinematographer = cinematographer.replace(\"\\n\", \"\").strip()\n",
    "                cinematographer_anchor = div.find_next('table').tbody.tr.td.a['href']\n",
    "                print(Fore.GREEN + 'Cinematographer')\n",
    "            if cin_flag == False:\n",
    "                cinematographer = np.nan\n",
    "                cinematographer_anchor = np.nan\n",
    "                print(Fore.RED + 'Cinematographer')\n",
    "          except:\n",
    "            cinematographer = np.nan\n",
    "            cinematographer_anchor = np.nan\n",
    "            print(Fore.RED + 'Cinematographer')\n",
    "            \n",
    "          '''\n",
    "              MUSIC BY\n",
    "          '''\n",
    "          try: \n",
    "            music_flag = False\n",
    "            divs = cast_html.find_all('h4')\n",
    "            for div in divs:\n",
    "              if 'Music by' in div.text:\n",
    "                music_flag = True\n",
    "                musician = div.find_next('table').tbody.tr.td.a.text.strip()\n",
    "                musician = musician.replace(\"\\n\", \"\")\n",
    "                musician_anchor = div.find_next('table').tbody.tr.td.a['href']\n",
    "                print(Fore.GREEN + 'Musician')\n",
    "            if music_flag == False:\n",
    "                musician = np.nan\n",
    "                musician_anchor = np.nan\n",
    "                print(Fore.RED + 'Musician')\n",
    "          except:\n",
    "            musician = np.nan\n",
    "            musician_anchor = np.nan\n",
    "            print(Fore.RED + 'Musician')\n",
    "\n",
    "          '''\n",
    "              PRODUCTION DESIGN\n",
    "          '''\n",
    "          try: \n",
    "            prod_flag = False\n",
    "            divs = cast_html.find_all('h4')\n",
    "            for div in divs:\n",
    "              if 'Production Design by' in div.text:\n",
    "                prod_flag = True\n",
    "                prod_designer = div.find_next('table').tbody.tr.td.a.text.strip()\n",
    "                prod_designer = prod_designer.replace(\"\\n\", \"\")\n",
    "                prod_designer_anchor = div.find_next('table').tbody.tr.td.a['href']\n",
    "                print(Fore.GREEN + 'Production Designer')\n",
    "            if prod_flag == False:\n",
    "                prod_designer = np.nan\n",
    "                prod_designer_anchor = np.nan\n",
    "                print(Fore.RED + 'Production Designer')\n",
    "          except:\n",
    "            prod_designer = np.nan\n",
    "            prod_designer_anchor = np.nan\n",
    "            print(Fore.RED + 'Production Designer')\n",
    "            \n",
    "          '''\n",
    "              SET DECORATOR\n",
    "          '''\n",
    "          try: \n",
    "            set_flag = False\n",
    "            divs = cast_html.find_all('h4')\n",
    "            for div in divs:\n",
    "              if 'Set Decoration by' in div.text:\n",
    "                set_flag = True\n",
    "                set_decorator = div.find_next('table').tbody.tr.td.a.text.strip()\n",
    "                set_decorator = set_decorator.replace(\"\\n\", \"\")\n",
    "                set_decorator_anchor = div.find_next('table').tbody.tr.td.a['href']\n",
    "                print(Fore.GREEN + 'Set Decorator')\n",
    "            if set_flag == False:\n",
    "                set_decorator = np.nan\n",
    "                set_decorator_anchor = np.nan\n",
    "                print(Fore.RED + 'Set Decorator')\n",
    "          except:\n",
    "            set_decorator = np.nan\n",
    "            set_decorator_anchor = np.nan\n",
    "            print(Fore.RED + 'Set Decorator')\n",
    "\n",
    "\n",
    "          '''\n",
    "              COSTUME DESIGN\n",
    "          '''\n",
    "          try: \n",
    "            costume_flag = False\n",
    "            divs = cast_html.find_all('h4')\n",
    "            for div in divs:\n",
    "              if 'Costume Design by' in div.text:\n",
    "                costume_flag = True\n",
    "                costume_designer = div.find_next('table').tbody.tr.td.a.text.strip()\n",
    "                costume_designer = costume_designer.replace(\"\\n\", \"\")\n",
    "                costume_designer_anchor = div.find_next('table').tbody.tr.td.a['href']\n",
    "                print(Fore.GREEN + 'Costume Designer')\n",
    "            if costume_flag == False:\n",
    "              costume_designer = np.nan\n",
    "              costume_designer_anchor = np.nan\n",
    "              print(Fore.RED + 'Costume Designer')\n",
    "\n",
    "          except:\n",
    "            costume_designer = np.nan\n",
    "            costume_designer_anchor = np.nan\n",
    "            print(Fore.RED + 'Costume Designer')\n",
    "            \n",
    "            \n",
    "          '''\n",
    "              GRAB SEQUELS\n",
    "          '''\n",
    "          def return_values(follows_count):\n",
    "              follows = []\n",
    "              for val in follows_count:\n",
    "                  if \"Follows\" in val:\n",
    "                      follows.append(re.sub(\"\\D\", \"\", val))\n",
    "              if follows:\n",
    "                  sequels = []\n",
    "                  count = int(follows[0])\n",
    "                  containers = sequel_html.find(\"a\", {\"id\": \"follows\"}).parent.findAll('div')\n",
    "                  counter = 0\n",
    "                  for container in containers:\n",
    "                      counter +=1\n",
    "                      if counter > int(count):\n",
    "                          break\n",
    "                      else:\n",
    "                          sequels.append(container.a.text)\n",
    "              return sequels\n",
    "          try:\n",
    "              @retry((ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2, backoff=2)\n",
    "              def get_sequel():\n",
    "                  sequel = get(\"https://www.imdb.com/\" + profile + \"movieconnections\")\n",
    "                  return sequel\n",
    "              sequel = get_sequel()\n",
    "              sequel_html = BeautifulSoup(sequel.text, 'html.parser')\n",
    "              try:\n",
    "                  follows_count = sequel_html.find('a', attrs = {'href':'#follows'})\n",
    "                  follows_count = sequel_html.find('a', attrs = {'href':'#follows'}).parent.text.split(\"\\n\")\n",
    "                  sequels = return_values(follows_count)\n",
    "                  print(Fore.GREEN + 'Sequel')\n",
    "              except:\n",
    "                  sequels = np.nan\n",
    "                  print(Fore.RED + 'Sequel')\n",
    "          except:\n",
    "              sequels = np.nan\n",
    "              print(Fore.RED + 'Sequel')\n",
    "          \n",
    "          \n",
    "          '''\n",
    "              GET PRODUCTION COMPANIES\n",
    "          '''\n",
    "\n",
    "          @retry((ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2, backoff=2)\n",
    "          def get_production():\n",
    "              production = get(\"https://www.imdb.com/\" + profile + \"companycredits\")\n",
    "              return production\n",
    "          production = get_production()\n",
    "          production_html = BeautifulSoup(production.text, 'html.parser')\n",
    "          try:\n",
    "              production_comps = []\n",
    "              production_companies = production_html.find(\"div\", {\"id\": \"company_credits_content\"}).ul.findAll('a')\n",
    "              for value in production_companies:\n",
    "                production_comps.append(value.text)\n",
    "              production_companies = production_comps\n",
    "              print(Fore.GREEN + 'Production COs')\n",
    "          except:\n",
    "              production_companies = np.nan\n",
    "              print(Fore.RED + 'Production COs')\n",
    "\n",
    "\n",
    "          '''\n",
    "              GET SCREEN WRITERS\n",
    "          '''\n",
    "          try:\n",
    "              headers = cast_html.find_all('h4', class_='dataHeaderWithBorder')\n",
    "              for idx, value in enumerate(headers):\n",
    "                if re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", value.text.replace(\"\\n\", \"\").strip()) == 'Writing Credits':\n",
    "                  index = idx\n",
    "              writing_header = headers[index]\n",
    "              \n",
    "              credit_containers = writing_header.find_next('table')\n",
    "              writers_x = credit_containers.tbody.findAll('tr')\n",
    "              cleaned_writers = []\n",
    "              screen_anchors = []\n",
    "              screen_credits = []\n",
    "\n",
    "              for writer in writers_x:\n",
    "                if writer.find('td', attrs = {'colspan':'3'}):\n",
    "                  continue\n",
    "                else:\n",
    "                  answer = writer.find('td', class_ = 'name').a.text\n",
    "                  answer = answer.strip()\n",
    "                  cleaned_writers.append(answer)\n",
    "                  try:\n",
    "                    anchor = writer.find('td', class_ = 'name').a['href']\n",
    "                    screen_anchors.append(anchor)\n",
    "                  except:\n",
    "                    screen_anchors.append(np.nan)\n",
    "                  try:\n",
    "                    credit = writer.find('td', class_='credit').text.strip()\n",
    "                  except:\n",
    "                    credit = np.nan\n",
    "                  screen_credits.append(credit)\n",
    "              screen_writers = cleaned_writers\n",
    "              print(Fore.GREEN + 'Screen Writers')\n",
    "          except Exception as e:\n",
    "              print(f\"Error: {e}\")\n",
    "              screen_writers = np.nan\n",
    "              screen_anchors = np.nan\n",
    "              screen_credits = np.nan\n",
    "              print(Fore.RED + 'Screen Writers')\n",
    "\n",
    "          '''\n",
    "              GET PRODUCERS\n",
    "          '''\n",
    "          try:\n",
    "              headers = cast_html.find_all('h4', class_='dataHeaderWithBorder')\n",
    "              for idx, value in enumerate(headers):\n",
    "                if value.text.strip() == 'Produced by':\n",
    "                  index = idx\n",
    "              writing_header = headers[index]\n",
    "              \n",
    "              credit_containers = writing_header.find_next('table')\n",
    "              writers_x = credit_containers.tbody.findAll('tr')\n",
    "              cleaned_producers = []\n",
    "              prod_anchors = []\n",
    "              prod_credits = []\n",
    "\n",
    "              for writer in writers_x:\n",
    "                if writer.find('td', attrs = {'colspan':'3'}):\n",
    "                  continue\n",
    "                else:\n",
    "                  answer = writer.find('td', class_ = 'name').text.strip()\n",
    "                  answer = answer.strip()\n",
    "                  cleaned_producers.append(answer)\n",
    "                  \n",
    "                  try:\n",
    "                    credit = writer.find('td', class_ = 'credit').text.strip()\n",
    "                    prod_credits.append(credit)\n",
    "                  except:\n",
    "                    prod_credits.append(np.nan)\n",
    "                  try:\n",
    "                    anchor = writer.find('td', class_ = 'name').a['href']\n",
    "                    prod_anchors.append(anchor)\n",
    "                  except:\n",
    "                    prod_anchors.append(np.nan)\n",
    "              producers = cleaned_producers\n",
    "              print(Fore.GREEN + 'Producers')\n",
    "          except:\n",
    "              producers = np.nan\n",
    "              prod_anchors = np.nan\n",
    "              prod_credits = np.nan\n",
    "              print(Fore.RED + 'Producers')\n",
    "              \n",
    "\n",
    "              \n",
    "          '''\n",
    "              GET BUDGET\n",
    "          '''\n",
    "\n",
    "          try:\n",
    "              bo_budget = details_html.find(text='Budget:').parent.findNext('span').decompose()\n",
    "              budget = details_html.find(text='Budget:').parent.parent.text.strip()\n",
    "              movie_budget = budget.replace(',', '').replace(\"Budget:\", \"\")\n",
    "              print(Fore.GREEN + 'Budget: {}'.format(movie_budget))\n",
    "\n",
    "          except:\n",
    "              movie_budget = np.nan\n",
    "              print(Fore.RED + 'Budget')\n",
    "\n",
    "\n",
    "\n",
    "          '''\n",
    "              GET RELEASE DATES\n",
    "          '''\n",
    "          try:\n",
    "              details_html.find(text='Release Date:').parent.findNext('span').decompose()\n",
    "              date = details_html.find(text='Release Date:').parent.parent.text.strip()\n",
    "              date = re.sub(r'\\([^)]*\\)', '', date.replace(\"Release Date:\", \"\"))[:-1]\n",
    "              release_date = date\n",
    "              print(Fore.GREEN + 'Release: {}'.format(date))\n",
    "          except:\n",
    "              release_date = np.nan\n",
    "              print(Fore.RED + 'Release')\n",
    "\n",
    "\n",
    "          '''\n",
    "              GET GENRE\n",
    "          '''\n",
    "          try:\n",
    "              genres = container.find('div', class_ = 'lister-item-content').p.find('span', class_ = 'genre').text.strip().split()\n",
    "              genre_list = []\n",
    "              for genre in genres:\n",
    "                genre_list.append(genre.replace(\",\", \"\").strip())\n",
    "              movie_genre = genre_list\n",
    "              print(Fore.GREEN + 'Genre: {}'.format(genre))\n",
    "          except:\n",
    "              movie_genre = np.nan\n",
    "              print(Fore.RED + 'Genre')\n",
    "\n",
    "          '''\n",
    "              GET SPECIAL EFFECT COMPANIES\n",
    "          '''\n",
    "\n",
    "          try:\n",
    "              comps_x = production_html.find(\"h4\", {\"id\": \"specialEffects\"}).findNext('ul').findAll('li')\n",
    "              cleaned_special_effects = []\n",
    "              for comp in comps_x:\n",
    "                  cleaned_special_effects.append(comp.a.text)\n",
    "              special_effects = cleaned_special_effects\n",
    "              print(Fore.GREEN + 'Special Effects COs')\n",
    "          except:\n",
    "            special_effects = np.nan\n",
    "\n",
    "          '''\n",
    "              GET MPAA RATING\n",
    "          '''\n",
    "          try:\n",
    "              mpaa = container.find('div', class_='lister-item-content').p.find('span', class_ = 'certificate').text\n",
    "              print(Fore.GREEN + 'MPAA: {}'.format(mpaa))\n",
    "          except:\n",
    "              mpaa = np.nan\n",
    "              print(Fore.RED + 'MPAA')\n",
    "\n",
    "          '''\n",
    "            DISTRIBUTOR\n",
    "          '''\n",
    "          try:\n",
    "            distributor = production_html.find('h4', {'id': 'distributors'}).find_next('ul').li.a.text\n",
    "            print(Fore.GREEN + 'Distributor')\n",
    "          except:\n",
    "            distributor = np.nan\n",
    "            print(Fore.RED + 'Distributor')\n",
    "            \n",
    "            \n",
    "\n",
    "          '''\n",
    "            COUNT NUMBER OF CAST & CREW\n",
    "          '''\n",
    "          try:\n",
    "            # find all headers for cast & crew\n",
    "            headers = cast_html.find_all('h4', class_='dataHeaderWithBorder')\n",
    "            full_cast_dict = {}\n",
    "            for header in headers:\n",
    "              try:\n",
    "                if header.get('id')=='cast':\n",
    "                  cast_name = 'Cast'\n",
    "                  cast = len(cast_html.find('table', class_='cast_list').find_all('tr', {'class':'odd'}))\n",
    "                  cast = cast + len(cast_html.find('table', class_='cast_list').find_all('tr', {'class':'even'}))\n",
    "                  full_cast_dict[cast_name] = cast\n",
    "                else:\n",
    "                  cast = header.find_next('table').find_all('td', {'class': 'name'})\n",
    "                  cast_name = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", header.text.strip()).replace(\"By\", \"\").replace(\"by\", \"\").strip()\n",
    "                  full_cast_dict[cast_name] = len(cast)\n",
    "              except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                full_cast_dict[header] = np.nan\n",
    "                print(Fore.RED + 'Cast Count')\n",
    "            print(Fore.GREEN + 'Cast Count')\n",
    "          except Exception as e:\n",
    "#             print(f\"Error: {e}\")\n",
    "            full_cast_dict = np.nan\n",
    "            print(Fore.RED + 'Cast Count')\n",
    "            \n",
    "            \n",
    "          '''\n",
    "            COUNT NUMBER OF COMPANIES\n",
    "          '''\n",
    "          try:\n",
    "            # find all headers for cast & crew\n",
    "            headers = production_html.find_all('h4', class_='dataHeaderWithBorder')\n",
    "            full_comp_dict = {}\n",
    "            for header in headers:\n",
    "              comps = header.find_next('ul').find_all('li')\n",
    "              comp_name = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", header.text.strip()).replace(\"By\", \"\").replace(\"by\", \"\").strip()\n",
    "              full_comp_dict[comp_name] = len(comps)\n",
    "            print(Fore.GREEN + 'Company Count')\n",
    "          except Exception as e:\n",
    "#             print(f\"Error: {e}\")\n",
    "            full_comps_dict = np.nan\n",
    "            print(Fore.RED + 'Company Count')\n",
    "            \n",
    "            \n",
    "          '''\n",
    "            COUNT NUMBER OF CONNECTIONS\n",
    "          '''\n",
    "          \n",
    "          # NUMBER OF VERSIONS\n",
    "          try:\n",
    "            elements = sequel_html.find('div', class_='jumpto').text.strip().replace(\"\\n\", \"\").replace(\"\\xa0\", \"\").replace(\"Jump to:\", \"\").split(\"|\")\n",
    "            versionFlag = False\n",
    "            for element in elements:\n",
    "              if 'Version' in element:\n",
    "                versionFlag = True\n",
    "                version_count = element[element.find(\"(\")+1:element.find(\")\")]\n",
    "            if versionFlag == False:\n",
    "              version_count=0\n",
    "              print(Fore.RED + \"Version\")\n",
    "            else:\n",
    "              print(Fore.GREEN + f\"Version: {version_count}\")\n",
    "          except Exception as e:\n",
    "#             print(f\"Error: {e}\")\n",
    "            print(Fore.RED + \"Version\")\n",
    "            version_count = 0\n",
    "          # NUMBER OF REFERENCES\n",
    "          try:\n",
    "            elements = sequel_html.find('div', class_='jumpto').text.strip().replace(\"\\n\", \"\").replace(\"\\xa0\", \"\").replace(\"Jump to:\", \"\").split(\"|\")\n",
    "            referenceFlag = False\n",
    "            for element in elements:\n",
    "              if 'References' in element:\n",
    "                referenceFlag = True\n",
    "                references_count = element[element.find(\"(\")+1:element.find(\")\")]\n",
    "            if referenceFlag == False:\n",
    "              references_count = 0\n",
    "              print(Fore.RED + \"References\")\n",
    "            else:\n",
    "              print(Fore.GREEN + f\"References Count: {references_count}\")\n",
    "          except:\n",
    "            references_count = 0\n",
    "            print(Fore.RED + \"References\")\n",
    "        \n",
    "          clear_output(wait = True)\n",
    "          movie = pd.DataFrame({\n",
    "            'name': [name],\n",
    "            'profile': [profile],\n",
    "            'budget': [movie_budget],\n",
    "            'plot': [plot_synopsis_content],\n",
    "            'summary': [summary],\n",
    "            'box_office': [dom_gross],\n",
    "            'int_office': [int_gross],\n",
    "            'runtime': [runtime],\n",
    "            'cast_members': [cast_members],\n",
    "            'cast_anchors': [cast_anchors],\n",
    "            'sequels': [sequels],\n",
    "            'pro_comp': [production_companies],\n",
    "            'directors': [directors],\n",
    "            'director_anchors': [director_anchors],\n",
    "            'director_credits': [director_credits],\n",
    "            'cinematographer': [cinematographer],\n",
    "            'cin_anch': [cinematographer_anchor],\n",
    "            'musician': [musician],\n",
    "            'musician_anchor': [musician_anchor],\n",
    "            'prod_designer': [prod_designer],\n",
    "            'prod_designer_anchor': [prod_designer_anchor],\n",
    "            'costume_designer': [costume_designer],\n",
    "            'costume_designer_anchor': [costume_designer_anchor],\n",
    "            'sequel': [sequels],\n",
    "            'screen_writers': [screen_writers],\n",
    "            'screen_anchors': [screen_anchors],\n",
    "            'screen_credits': [screen_credits],\n",
    "            'release': [release_date],\n",
    "            'genre': [movie_genre],\n",
    "            'spec_eff': [special_effects],\n",
    "            'distributor': [distributor],\n",
    "            'mpaa': [mpaa],\n",
    "            'sound_mix': [sound_mix],\n",
    "            'producers': [producers],\n",
    "            'prod_anchors': [prod_anchors],\n",
    "            'prod_credits': [prod_credits],\n",
    "            'stars': [stars],\n",
    "            'star_anchs': [star_anchs],\n",
    "            'cast_count': [full_cast_dict],\n",
    "            'comp_count': [full_comp_dict],\n",
    "            'version_count': [version_count],\n",
    "            'references_count': [references_count],\n",
    "            'languages': [languages]\n",
    "          })\n",
    "          movies = movies.append(movie, ignore_index=True)\n",
    "          movies.to_csv(f\"{path}full_{thread}.csv\", index=False)\n",
    "  return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv(\"../../data/links.csv\")\n",
    "len(list(set(links['link'].values)))\n",
    "links = list(dict.fromkeys(list(links['link'].values)))\n",
    "links.insert(0, 'https://www.imdb.com/search/title/?title_type=feature&sort=boxoffice_gross_us,desc&count=250&ref_=adv_prv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thread(thread):\n",
    "  \"\"\"\n",
    "    Objective\n",
    "    ----------\n",
    "    Return parameters for scrapeMovies function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    thread : string\n",
    "      unique thread number.\n",
    "  \"\"\"\n",
    "  path = \"../../data/\"\n",
    "  total = len(links)\n",
    "  thread_length = int(len(links)/6)\n",
    "  if thread=='one':\n",
    "    result = links[:thread_length]\n",
    "  elif thread=='two':\n",
    "    result = links[thread_length:thread_length*2]\n",
    "  elif thread=='three':\n",
    "    result = links[thread_length*2:thread_length*3]\n",
    "  elif thread=='four':\n",
    "    result = links[thread_length*3:thread_length*4]\n",
    "  elif thread=='five':\n",
    "    result = links[thread_length*4:thread_length*5]\n",
    "  elif thread=='six':\n",
    "    result = links[thread_length*5:thread_length*6]\n",
    "  return result, path, thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mBeyond the Reach(12702)\n",
      "\u001b[31mPlot Synopsis\n",
      "\u001b[32mSummary\n",
      "\u001b[32mLanguages\n",
      "\u001b[32mBox Office Gross: $45895\n",
      "\u001b[32mWorldWide Box Office Gross: $1100432\n",
      "\u001b[32mRuntime : 91 min\n",
      "\u001b[32mSoundmix\n",
      "\u001b[32mStars\n",
      "\u001b[32mCast\n",
      "Anchors: ['/name/nm1515266/']\n",
      "\u001b[32mCinematographer\n",
      "\u001b[32mMusician\n",
      "\u001b[32mProduction Designer\n",
      "\u001b[32mSet Decorator\n",
      "\u001b[32mCostume Designer\n",
      "\u001b[31mSequel\n",
      "\u001b[32mProduction COs\n",
      "\u001b[32mScreen Writers\n",
      "\u001b[32mProducers\n",
      "\u001b[31mBudget\n",
      "\u001b[32mRelease:  17 April 2015\n",
      "\u001b[32mGenre: Thriller\n",
      "\u001b[32mSpecial Effects COs\n",
      "\u001b[32mMPAA: R\n",
      "\u001b[32mDistributor\n",
      "\u001b[32mCast Count\n",
      "\u001b[32mCompany Count\n",
      "\u001b[31mVersion\n",
      "\u001b[31mReferences\n"
     ]
    }
   ],
   "source": [
    "links, path, thread = thread('one')\n",
    "scrapeMovies(links, path, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
