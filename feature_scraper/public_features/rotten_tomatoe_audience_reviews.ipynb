{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from time import time\n",
    "from IPython.core.display import clear_output\n",
    "from warnings import warn\n",
    "import math\n",
    "# import cv2\n",
    "import os\n",
    "import time\n",
    "from functools import wraps\n",
    "from colorama import Fore\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import ElementNotVisibleException\n",
    "from requests import ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError\n",
    "from fake_useragent import UserAgent\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import numpy as np\n",
    "# Import dependencies\n",
    "from urllib.parse import quote\n",
    "from pprint import pprint\n",
    "from googlesearch import search \n",
    "import random\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry(ExceptionToCheck, tries=4, delay=3, backoff=2, logger=None):\n",
    "    \"\"\"Retry calling the decorated function using an exponential backoff.\n",
    "\n",
    "    http://www.saltycrane.com/blog/2009/11/trying-out-retry-decorator-python/\n",
    "    original from: http://wiki.python.org/moin/PythonDecoratorLibrary#Retry\n",
    "\n",
    "    :param ExceptionToCheck: the exception to check. may be a tuple of\n",
    "        exceptions to check\n",
    "    :type ExceptionToCheck: Exception or tuple\n",
    "    :param tries: number of times to try (not retry) before giving up\n",
    "    :type tries: int\n",
    "    :param delay: initial delay between retries in seconds\n",
    "    :type delay: int\n",
    "    :param backoff: backoff multiplier e.g. value of 2 will double the delay\n",
    "        each retry\n",
    "    :type backoff: int\n",
    "    :param logger: logger to use. If None, print\n",
    "    :type logger: logging.Logger instance\n",
    "    \"\"\"\n",
    "    def deco_retry(f):\n",
    "\n",
    "        @wraps(f)\n",
    "        def f_retry(*args, **kwargs):\n",
    "            mtries, mdelay = tries, delay\n",
    "            while mtries > 1:\n",
    "                try:\n",
    "                    return f(*args, **kwargs)\n",
    "                except ExceptionToCheck:\n",
    "                    msg = \"%s, Retrying in %d seconds...\" % (str(ExceptionToCheck), mdelay)\n",
    "                    if logger:\n",
    "                        #logger.exception(msg) # would print stack trace\n",
    "                        logger.warning(msg)\n",
    "                    else:\n",
    "                        print(msg)\n",
    "                    time.sleep(mdelay)\n",
    "                    mtries -= 1\n",
    "                    mdelay *= backoff\n",
    "            return f(*args, **kwargs)\n",
    "\n",
    "        return f_retry  # true decorator\n",
    "\n",
    "    return deco_retry  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data(fixed)/datasets/rotten_tomatoe_df.csv\",index_col=0)\n",
    "df = df.drop(df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one,two,three,four,five,six,seven = df[:500],df[500:1000], df[1000:1500],df[1500:2000],df[2000:2500], df[2500:3000], df[3000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selenium Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WINDOWS\n",
    "# chromedriver_path = str(\"\"\"C:/Users/Brian/Desktop/chromedriver.exe\"\"\")\n",
    "# user_data_path = \"C:/Users/Brian/AppData/Local/Google/Chrome/User Data/Thread_Five\"\n",
    "\n",
    "# MAC\n",
    "chromedriver_path = \"/Users/brianphelps/Desktop/chromedriver\"\n",
    "user_data_path = \"/Users/brianphelps/Library/Application Support/Google/Chrome/Thread_SWOOPS\"\n",
    "\n",
    "# OPTIONS\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"no-sandbox\")\n",
    "options.add_argument(\"disable-dev-shm-usage\")\n",
    "options.add_argument(\"headless\")\n",
    "# options.add_argument(f\"user-data-dir={user_data_path}\")\n",
    "# driver = webdriver.Chrome(f\"{chromedriver_path}\", chrome_options=options)\n",
    "# driver.get('https://pro.imdb.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RottenTomatoeSpider(object):\n",
    "  def __init__(self, df):\n",
    "    \"\"\"Crawl Rotten Tomatoe search results\n",
    "\n",
    "    This class is used to crawl Rotten Tomatoe's reviews using Selenium and BeautifulSoup.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    chromedriver_path = \"/Users/brianphelps/Desktop/chromedriver\"\n",
    "    user_data_path = \"/Users/brianphelps/Library/Application Support/Google/Chrome/Thread_SWOOPS\"\n",
    "\n",
    "    # OPTIONS\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"no-sandbox\")\n",
    "    options.add_argument(\"disable-dev-shm-usage\")\n",
    "    options.add_argument(\"headless\")\n",
    "#     options.add_argument(f\"user-data-dir={user_data_path}\")\n",
    "    \n",
    "    self.options = options\n",
    "    self.chromedriver_path = chromedriver_path\n",
    "    self.data = df\n",
    "    self.review_dataframe = pd.DataFrame()\n",
    "\n",
    "  def critic_reviews(self, thread_name):\n",
    "    \"\"\"Get the web page's source code\n",
    "\n",
    "    Args:\n",
    "        thread_name (str): Filename of thread to save\n",
    "\n",
    "    Returns:\n",
    "        dataframe: Critic review results\n",
    "    \"\"\"\n",
    "    counter=0\n",
    "    for row in self.data.itertuples():\n",
    "      counter+=1\n",
    "      profile = row.profile\n",
    "      url = row.url\n",
    "      name = row.name\n",
    "      year = int(row.Year)\n",
    "      '''\n",
    "          GET REVIEWS\n",
    "      '''\n",
    "\n",
    "      driver = webdriver.Chrome(f\"{self.chromedriver_path}\", chrome_options=self.options)\n",
    "\n",
    "      @retry((ConnectionResetError,TimeoutException,ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2, backoff=2)\n",
    "      def driver_reviews(url):\n",
    "        driver.get(f\"{url}\")\n",
    "      driver_reviews(url+'/reviews')\n",
    "\n",
    "      src = driver.page_source\n",
    "      parser = BeautifulSoup(src, 'lxml')\n",
    "      base_url = 'https://www.rottentomatoes.com/'\n",
    "\n",
    "      try:\n",
    "        num_pages = int(parser.find('span', class_='pageInfo').text.replace(\"Page 1 of \", \"\").strip())\n",
    "      except:\n",
    "        num_pages = 1\n",
    "\n",
    "\n",
    "      review_count=0\n",
    "      for i in range(num_pages):\n",
    "        src = driver.page_source\n",
    "        parser = BeautifulSoup(src, 'lxml')\n",
    "        try:\n",
    "          next_link_one = parser.find('span', class_='pageInfo').parent.find_all('a')[1]['href']\n",
    "          next_link = base_url+next_link_one\n",
    "        except:\n",
    "          next_link_one = 'nan'\n",
    "          next_link = np.nan\n",
    "\n",
    "        try:\n",
    "          reviews_container = parser.find('div', class_='review_table')\n",
    "          review_containers = reviews_container.find_all('div', class_='review_table_row')\n",
    "        except:\n",
    "          driver.quit()\n",
    "          break\n",
    "\n",
    "        movie_reviews = pd.DataFrame()\n",
    "\n",
    "        for review in review_containers:\n",
    "          # FIND SENTIMENT\n",
    "          fresh = review.find('div', class_='fresh')\n",
    "          if fresh:\n",
    "            sentiment = 'fresh'\n",
    "          else:\n",
    "            sentiment = 'rotten'\n",
    "              \n",
    "          # TOP CRITIC BOOLEAN\n",
    "          top = review.find('span', class_='glyphicon-star')\n",
    "          if top:\n",
    "            top_critic = True\n",
    "          else:\n",
    "            top_critic = False\n",
    "\n",
    "          try:\n",
    "            date = review.find('div', class_='review-date').text.strip()\n",
    "          except:\n",
    "            date = np.nan\n",
    "            \n",
    "          try:\n",
    "            the_review = review.find('div', class_='the_review').text.strip()\n",
    "          except:\n",
    "            the_review = np.nan\n",
    "\n",
    "          temp = pd.DataFrame({\n",
    "            'date': [date],\n",
    "            'review': [the_review],\n",
    "            'sentiment': [sentiment],\n",
    "            'movie': [name],\n",
    "            'profile': [profile],\n",
    "            'top_critic': [top_critic]\n",
    "          })\n",
    "          review_count+=1\n",
    "          self.review_dataframe = self.review_dataframe.append(temp, ignore_index=True)\n",
    "          print(Fore.GREEN + name)\n",
    "          print(Fore.GREEN + f\"Reviews: {review_count}\")\n",
    "          print(Fore.GREEN + f\"{counter}/{len(self.data)}\")\n",
    "          clear_output(wait = True)\n",
    "          \n",
    "          \n",
    "          \n",
    "#         self.review_dataframe.to_csv(f\"./rotten_tomatoe_critic_reviews_{thread_name}.csv\", index=False)\n",
    "        if next_link_one not in [\"#\",\"nan\"] and type(next_link)==str:\n",
    "          driver_reviews(next_link)\n",
    "        else:\n",
    "          driver.quit()\n",
    "          \n",
    "    return self.review_dataframe\n",
    "\n",
    "  def audience_reviews(self, thread):\n",
    "    \"\"\"Search Rotten Tomatoe Audience Reviews\n",
    "\n",
    "    Returns:\n",
    "        dataframe: Audience Reviews\n",
    "    \"\"\"\n",
    "\n",
    "    counter=0\n",
    "    for row in self.data.itertuples():\n",
    "      counter+=1\n",
    "      profile = row.profile\n",
    "      url = row.url\n",
    "      name = row.name\n",
    "      year = int(row.Year)\n",
    "      '''\n",
    "          GET REVIEWS\n",
    "      '''\n",
    "\n",
    "      driver = webdriver.Chrome(f\"{self.chromedriver_path}\", chrome_options=self.options)\n",
    "\n",
    "      @retry((ConnectionResetError,TimeoutException,ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2, backoff=2)\n",
    "      def driver_reviews(url):\n",
    "        driver.get(f\"{url}\")\n",
    "      driver_reviews(url+'/reviews?type=user')\n",
    "\n",
    "      src = driver.page_source\n",
    "      parser = BeautifulSoup(src, 'lxml')\n",
    "      base_url = 'https://www.rottentomatoes.com/'\n",
    "\n",
    "\n",
    "      current_movie_reviews = pd.DataFrame()\n",
    "      review_count=0\n",
    "\n",
    "      next_page_btn = True\n",
    "\n",
    "      while next_page_btn == True:\n",
    "\n",
    "        src = driver.page_source\n",
    "        parser = BeautifulSoup(src, 'lxml')\n",
    "        for button in parser.find_all(\"button\", class_='hide'): \n",
    "          #delete all hidden buttons\n",
    "          button.decompose()\n",
    "\n",
    "        try:\n",
    "          #Delete Element From DOM\n",
    "          #PYTHON\n",
    "          for button in parser.find_all(\"button\", class_='hide'): \n",
    "            #delete all hidden buttons\n",
    "            button.decompose()\n",
    "          #JS\n",
    "          driver.execute_script(\"\"\"\n",
    "            var elements = document.getElementsByClassName('prev-next-paging__button-right hide');\n",
    "            for(i=0;i<elements.length;i++){\n",
    "              elements[i].parentNode.removeChild(elements[i]);\n",
    "            }\n",
    "          \"\"\")\n",
    "          next_link = parser.find('button', class_='prev-next-paging__button-right')\n",
    "        except:\n",
    "          next_link = 'nan'\n",
    "          next_page_btn = False\n",
    "\n",
    "        try:\n",
    "          reviews_container = parser.find('ul', class_='audience-reviews')\n",
    "          review_containers = reviews_container.find_all('li', class_='audience-reviews__item')\n",
    "        except:\n",
    "          driver.quit()\n",
    "          break\n",
    "\n",
    "        for review in review_containers:\n",
    "\n",
    "          full = len(review.find_all('span', class_='star-display__filled'))\n",
    "          half = len(review.find_all('span', class_='star-display__half'))\n",
    "          sentiment = 0\n",
    "          if full:\n",
    "            for i in range(full):\n",
    "              sentiment+=1\n",
    "          if half:\n",
    "            for i in range(half):\n",
    "              sentiment+=.5\n",
    "\n",
    "\n",
    "          try:\n",
    "            date = review.find('span', class_='audience-reviews__duration').text.strip()\n",
    "          except:\n",
    "            date = np.nan\n",
    "          try:\n",
    "            the_review = review.find('p').text.strip()\n",
    "          except:\n",
    "            the_review = np.nan\n",
    "\n",
    "          temp = pd.DataFrame({\n",
    "            'date': [date],\n",
    "            'review': [the_review],\n",
    "            'sentiment': [sentiment],\n",
    "            'movie': [name],\n",
    "            'profile': [profile]\n",
    "          })\n",
    "          review_count+=1\n",
    "\n",
    "          current_movie_reviews = current_movie_reviews.append(temp, ignore_index=True).drop_duplicates()\n",
    "          print(Fore.GREEN + name)\n",
    "          print(Fore.GREEN + f\"Reviews: {review_count}\")\n",
    "          print(Fore.GREEN + f\"{counter}/{len(self.data)}\")\n",
    "          clear_output(wait = True)\n",
    "        if next_link!='nan':\n",
    "          try:\n",
    "            driver.execute_script(\"\"\"\n",
    "              var element = document.getElementsByClassName('prev-next-paging__button-right')[0];\n",
    "              if(element.classList.contains('hide')){\n",
    "\n",
    "              }else{\n",
    "                element.click()\n",
    "              }\n",
    "            \"\"\")\n",
    "            time.sleep(1)\n",
    "          except:\n",
    "            next_page_btn = False\n",
    "        if self.review_dataframe.shape[0] > 250000:\n",
    "          self.review_dataframe.to_csv(f\"{thread}_{counter}.csv\")\n",
    "          self.review_dataframe = pd.DataFrame()\n",
    "        self.review_dataframe = self.review_dataframe.append(current_movie_reviews, ignore_index=True).drop_duplicates()\n",
    "        print(Fore.GREEN + name)\n",
    "        print(Fore.GREEN + f\"Reviews: {len(self.review_dataframe)}\")\n",
    "        print(Fore.GREEN + f\"{counter}/{len(self.data)}\")\n",
    "        clear_output(wait = True)\n",
    "      driver.quit()\n",
    "    return self.review_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spider.review_dataframe.profile.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_dataframe_one = spider.review_dataframe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: net::ERR_NAME_NOT_RESOLVED\n  (Session info: headless chrome=86.0.4240.183)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-20b47060e515>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mspider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRottenTomatoeSpider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mone_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudience_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'one'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-a8a1526d1d3f>\u001b[0m in \u001b[0;36maudience_reviews\u001b[0;34m(self, thread)\u001b[0m\n\u001b[1;32m    151\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mdriver_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0mdriver_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/reviews?type=user'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d5d36b2de305>\u001b[0m in \u001b[0;36mf_retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mmtries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mExceptionToCheck\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s, Retrying in %d seconds...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExceptionToCheck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-a8a1526d1d3f>\u001b[0m in \u001b[0;36mdriver_reviews\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    150\u001b[0m       \u001b[0;34m@\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConnectionResetError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTimeoutException\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReadTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConnectTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mdriver_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m       \u001b[0mdriver_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/reviews?type=user'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \"\"\"\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/opt/anaconda3/envs/thesis/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: unknown error: net::ERR_NAME_NOT_RESOLVED\n  (Session info: headless chrome=86.0.4240.183)\n"
     ]
    }
   ],
   "source": [
    "one=one.reset_index(drop=True)\n",
    "one = one.iloc[6:]\n",
    "spider = RottenTomatoeSpider(one)\n",
    "one_reviews = spider.audience_reviews('one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
