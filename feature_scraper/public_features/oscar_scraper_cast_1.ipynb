{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from time import time\n",
    "from IPython.core.display import clear_output\n",
    "from warnings import warn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import time\n",
    "from functools import wraps\n",
    "from colorama import Fore\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import ElementNotVisibleException\n",
    "from requests import ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry(ExceptionToCheck, tries=20, delay=3, backoff=2, logger=None):\n",
    "  \"\"\"\n",
    "    Modified from source: http://wiki.python.org/moin/PythonDecoratorLibrary#Retry\n",
    "\n",
    "    Objective\n",
    "    ----------\n",
    "    Exponential backoff function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ExceptionToCheck : Exception or tuple\n",
    "      the exception to check. may be a tuple of exceptions to check\n",
    "      Possible values:\n",
    "        ConnectionResetError, (TimeoutError, ConnectionError)\n",
    "    tries : int\n",
    "      number of times to try (not retry) before giving up\n",
    "    delay : int\n",
    "      initial delay between retries in seconds\n",
    "    backoff: int\n",
    "      backoff multiplier\n",
    "      E.g. value of 2 will double the delay each retry\n",
    "    logger : logging.Logger instance\n",
    "      logger to use\n",
    "  \"\"\"\n",
    "  def deco_retry(f):\n",
    "    @wraps(f)\n",
    "    def f_retry(*args, **kwargs):\n",
    "      mtries, mdelay = tries, delay\n",
    "      while mtries > 1:\n",
    "        try:\n",
    "          return f(*args, **kwargs)\n",
    "        except ExceptionToCheck:\n",
    "          msg = \"%s, Retrying in %d seconds...\" % (str(ExceptionToCheck), mdelay)\n",
    "          if logger:\n",
    "            #logger.exception(msg) # would print stack trace\n",
    "            logger.warning(msg)\n",
    "          else:\n",
    "            print(msg)\n",
    "          time.sleep(mdelay)\n",
    "          mtries -= 1\n",
    "          mdelay *= backoff\n",
    "        return f(*args, **kwargs)\n",
    "      return f_retry  # true decorator\n",
    "  return deco_retry  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = pd.DataFrame()\n",
    "thread_one = pd.read_csv(\"../data/thread_one.csv\")\n",
    "thread_two = pd.read_csv(\"../data/thread_two.csv\")\n",
    "threads = threads.append(thread_one, ignore_index=True)\n",
    "threads = threads.append(thread_two, ignore_index=True)\n",
    "threads = threads.dropna(subset=['cast_members', 'cast_anchors', 'directors', 'director_anchors'])\n",
    "\n",
    "import ast\n",
    "members_list = []\n",
    "anchors_list = []\n",
    "directors_list = []\n",
    "dir_anchors_list = []\n",
    "for row in threads.itertuples():\n",
    "  #change strings to lists\n",
    "  cast = ast.literal_eval(row.cast_members)\n",
    "  anchors = ast.literal_eval(row.cast_anchors)\n",
    "  members_list.append(cast[:15])\n",
    "  anchors_list.append(anchors[:15])\n",
    "  #change strings to lists\n",
    "  directors = ast.literal_eval(row.directors)\n",
    "  dir_anchors = ast.literal_eval(row.director_anchors)\n",
    "  directors_list.append(directors)\n",
    "  dir_anchors_list.append(dir_anchors)\n",
    "threads['cast_anchors'] = anchors_list\n",
    "threads['cast_members'] = members_list\n",
    "threads['directors'] = directors_list\n",
    "threads['director_anchors'] = dir_anchors_list\n",
    "\n",
    "threads = threads[['name', 'box_office', 'cast_anchors', 'cast_members',\n",
    "       'director_anchors', 'directors', 'release']]\n",
    "\n",
    "cast_df = threads[['name', 'cast_anchors', 'cast_members', 'release', 'box_office']]\n",
    "directors_df = threads[['name', 'box_office', 'director_anchors', 'directors', 'release']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directors: 13563\n"
     ]
    }
   ],
   "source": [
    "# dir_df = pd.DataFrame()\n",
    "# #create director dictionary\n",
    "# counter=0\n",
    "# for index, row in enumerate(directors_df.itertuples()):\n",
    "#   counter+=1\n",
    "#   anchors = row.director_anchors\n",
    "#   directors = row.directors\n",
    "#   for idx, value in enumerate(anchors):\n",
    "#     director = directors[idx]\n",
    "#     link = value\n",
    "#     temp = pd.DataFrame({\n",
    "#       'Director': [director],\n",
    "#       'Link': [link]\n",
    "#     })\n",
    "#     dir_df = dir_df.append(temp)\n",
    "#   if counter%1000==0:\n",
    "#     print(f\"{counter}/{len(directors_df)}\")\n",
    "#     clear_output(wait=True)\n",
    "# print(f\"Directors: {len(dir_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #drop duplicates\n",
    "# dir__clone = dir_df\n",
    "# dir_df = dir_df.drop_duplicates(keep='first')\n",
    "# #view duplicated rows based on name!\n",
    "# duplicateRowsDF = dir_df[dir_df.duplicated(['Director'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Billed: 183479\n"
     ]
    }
   ],
   "source": [
    "# fb_df = pd.DataFrame()\n",
    "# #create first billed dictionary\n",
    "# counter=0\n",
    "# for row in cast_df.itertuples():\n",
    "#   counter+=1\n",
    "#   anchors = row.cast_anchors\n",
    "#   actors = row.cast_members\n",
    "#   for idx, value in enumerate(anchors):\n",
    "#     link = value\n",
    "#     actor = actors[idx]\n",
    "#     temp = pd.DataFrame({\n",
    "#       'Actor': [actor],\n",
    "#       'Link': [link]\n",
    "#     })\n",
    "#     fb_df = fb_df.append(temp)\n",
    "#   if counter%1000==0:\n",
    "#     print(f\"{counter}/{len(cast_df)}\")\n",
    "#     clear_output(wait=True)\n",
    "# print(f\"First Billed: {len(fb_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #drop duplicates\n",
    "# fb_clone = fb_df\n",
    "# fb_df = fb_df.drop_duplicates(keep='first')\n",
    "# #view duplicated rows based on name!\n",
    "# duplicateRowsDF = fb_df[fb_df.duplicated(['Actor'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_df.to_csv(\"directors.csv\")\n",
    "# fb_df.to_csv(\"first_billed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_df = pd.read_csv(\"directors.csv\")\n",
    "dir_df = dir_df.drop(dir_df.columns[0], axis=1)\n",
    "\n",
    "fixed_dirs = []\n",
    "for row in dir_df.itertuples():\n",
    "  director = row.Director\n",
    "  director = director.strip()\n",
    "  fixed_dirs.append(director)\n",
    "dir_df['Director']=fixed_dirs\n",
    "fb_df = pd.read_csv(\"first_billed.csv\")\n",
    "fb_df = fb_df.drop(fb_df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grabOscars(actor, link, counter, sleep):\n",
    "  try:\n",
    "    #MACBOOK DATA\n",
    "#     options = webdriver.ChromeOptions()\n",
    "#     options.add_argument(\"no-sandbox\")\n",
    "#     options.add_argument(\"disable-dev-shm-usage\")\n",
    "#     options.add_argument(\"headless\")\n",
    "#     options.add_argument(\"user-data-dir=/Users/brianphelps/Library/Application Support/Google/Chrome/Thread_One\")\n",
    "#     driver = webdriver.Chrome(executable_path=\"/Users/brianphelps/Desktop/chromedriver\", chrome_options=options)\n",
    "    \n",
    "    #BASEMENT OFFICE DATA\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"no-sandbox\")\n",
    "    options.add_argument(\"disable-dev-shm-usage\")\n",
    "    # options.add_argument(\"headless\")\n",
    "    options.add_argument(\"user-data-dir=C:/Users/Brian/AppData/Local/Google/Chrome/User Data/Two\")\n",
    "    driver = webdriver.Chrome(\"C:\\\\Users\\Brian\\Downloads\\chromedriver.exe\", chrome_options=options)\n",
    "    \n",
    "    \n",
    "    @retry((ReadTimeout, ConnectTimeout, HTTPError, Timeout, ConnectionError), tries=20, delay=2, backoff=2)\n",
    "    def serve_link():\n",
    "      driver.get(f\"https://www.imdb.com{link}awards\")\n",
    "    serve_link()\n",
    "    \n",
    "\n",
    "    try:\n",
    "      sourcez = driver.page_source\n",
    "      cast_html = BeautifulSoup(sourcez, 'html.parser')\n",
    "      academy_awards = cast_html.find(text='Academy Awards, USA').parent.find_next('table', class_='awards').tbody.find_all('tr')\n",
    "      awards = pd.DataFrame()\n",
    "      for idx, award in enumerate(academy_awards):\n",
    "        year = academy_awards[idx].find_all(\"td\")[0].a.text.strip()\n",
    "        outcome = academy_awards[idx].find_all(\"td\")[1].b.text\n",
    "        award = academy_awards[idx].find_all(\"td\")[1].span.text\n",
    "        desc = academy_awards[idx].find_all(\"td\")[2].text.strip()\n",
    "        movie = academy_awards[idx].find_all(\"td\")[2].a.text\n",
    "        movie_year = academy_awards[idx].find_all(\"td\")[2].span.text\n",
    "        print(f\"Actor: {actor}\")\n",
    "        print(f\"Year: {year}\")\n",
    "        print(f\"Outcome: {outcome}\")\n",
    "        print(f\"Award: {award}\")\n",
    "        print(f\"Movie: {movie}\")\n",
    "        print(f\"Award_Year: {movie_year}\")\n",
    "        current_award = pd.DataFrame({\n",
    "          'actor': [actor],\n",
    "          'link': [link],\n",
    "          'year': [year],\n",
    "          'outcome': [outcome],\n",
    "          'award': [award],\n",
    "          'desc': [desc],\n",
    "          'movie': [movie],\n",
    "          'movie_year': [movie_year]\n",
    "        })\n",
    "        awards = awards.append(current_award)\n",
    "        print(Fore.GREEN + f\"{actor}: {award}\")\n",
    "        clear_output(wait=True)\n",
    "    except Exception as exceptor:\n",
    "      print(exceptor)\n",
    "      awards = pd.DataFrame({\n",
    "        'actor': [actor],\n",
    "        'link': [link],\n",
    "        'year': [np.nan],\n",
    "        'outcome': [np.nan],\n",
    "        'award': [np.nan],\n",
    "        'desc': [np.nan],\n",
    "        'movie': [np.nan],\n",
    "        'movie_year': [np.nan]\n",
    "      })\n",
    "      print(Fore.RED + f\"{actor}: {np.nan}\")\n",
    "      clear_output(wait=True)\n",
    "    driver.quit()\n",
    "\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    awards = pd.DataFrame({\n",
    "      'actor': [actor],\n",
    "      'link': [link],\n",
    "      'year': [np.nan],\n",
    "      'outcome': [np.nan],\n",
    "      'award': [np.nan],\n",
    "      'desc': [np.nan],\n",
    "      'movie': [np.nan],\n",
    "      'movie_year': [np.nan]\n",
    "    })\n",
    "    print(Fore.RED + f\"{actor}: {np.nan}\")\n",
    "    clear_output(wait=True)\n",
    "  \n",
    "  time.sleep(sleep)\n",
    "  return awards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# def runTest(thread):\n",
    "#   #TEST FIRST FEW DICT ITEMS\n",
    "#   subset = dict(itertools.islice(first_billed_dict.items(), 2))\n",
    "#   subset = {'Will Smith': '/name/nm0000226/'}\n",
    "#   counter = 0\n",
    "#   award_dataframe = pd.DataFrame()\n",
    "#   for key, val in enumerate(subset):\n",
    "#     counter+=1\n",
    "#     actor = val\n",
    "#     link = subset[val]\n",
    "#     info = grabOscars(actor, link, counter, 3, 1)\n",
    "#     award_dataframe = award_dataframe.append(info, ignore_index=True)\n",
    "#     award_dataframe.to_csv(f\"cast_oscars_{thread}.csv\")\n",
    "  \n",
    "# runTest(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6cddb20c55b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m#PARAMETERS - Actor, Link, Counter, Sleep Time, Thread #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrabOscars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0maward_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maward_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0maward_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cast_oscars_{thread}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-7b969a672990>\u001b[0m in \u001b[0;36mgrabOscars\u001b[0;34m(actor, link, counter, sleep)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mawards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "  GRAB OSCAR INFORMATION\n",
    "'''\n",
    "import itertools\n",
    "thread = 1\n",
    "\n",
    "if thread==1:\n",
    "  #THREAD ONE\n",
    "  fb_dfz = fb_df[:34331]\n",
    "elif thread==2:\n",
    "  #THREAD TWO\n",
    "  fb_df = fb_df[34331:68662]\n",
    "elif thread==3:\n",
    "  #THREAD THREE\n",
    "  fb_df = fb_df[68662:102993]\n",
    "  \n",
    "  \n",
    "counter = 0\n",
    "award_dataframe = pd.DataFrame()\n",
    "for idx, row in enumerate(fb_df.itertuples()):\n",
    "  counter+=1\n",
    "  actor = row.Actor\n",
    "  link = row.Link\n",
    "  #PARAMETERS - Actor, Link, Counter, Sleep Time, Thread #\n",
    "  info = grabOscars(actor, link, counter, 3)\n",
    "  award_dataframe = award_dataframe.append(info, ignore_index=True)\n",
    "  award_dataframe.to_csv(f\"cast_oscars_{thread}.csv\")\n",
    "print(f\"Thread {thread} complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"no-sandbox\")\n",
    "# options.add_argument(\"disable-dev-shm-usage\")\n",
    "# # options.add_argument(\"headless\")\n",
    "# options.add_argument(\"user-data-dir=/Users/brianphelps/Library/Application Support/Google/Chrome/Thread_One\")\n",
    "# driver = webdriver.Chrome(executable_path=\"/Users/brianphelps/Desktop/chromedriver\", chrome_options=options)\n",
    "# driver.get('https://pro.imdb.com')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
